{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ySCVPA73PiOI"
      },
      "outputs": [],
      "source": [
        "!pip install -q pyspark\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Build a Classification Model with Spark with a dataset of your choice"
      ],
      "metadata": {
        "id": "2_gDdlzqQmL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "import pandas as pd\n",
        "\n",
        "# Spark session\n",
        "spark = SparkSession.builder.appName(\"Classification\").getOrCreate()\n",
        "\n",
        "# Load and convert dataset\n",
        "data = load_breast_cancer()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['label'] = data.target\n",
        "spark_df = spark.createDataFrame(df)\n",
        "\n",
        "# Features\n",
        "vec_assembler = VectorAssembler(inputCols=data.feature_names.tolist(), outputCol=\"features\")\n",
        "assembled = vec_assembler.transform(spark_df)\n",
        "\n",
        "# Model\n",
        "lr = LogisticRegression(featuresCol='features', labelCol='label')\n",
        "model = lr.fit(assembled)\n",
        "\n",
        "# Prediction\n",
        "predictions = model.transform(assembled)\n",
        "predictions.select(\"label\", \"prediction\", \"probability\").show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDF1l3yEPtHo",
        "outputId": "6cdc020f-0cfe-4ccc-e3a4-1d316c265e37"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+-----------+\n",
            "|label|prediction|probability|\n",
            "+-----+----------+-----------+\n",
            "|    0|       0.0|  [1.0,0.0]|\n",
            "|    0|       0.0|  [1.0,0.0]|\n",
            "|    0|       0.0|  [1.0,0.0]|\n",
            "|    0|       0.0|  [1.0,0.0]|\n",
            "|    0|       0.0|  [1.0,0.0]|\n",
            "+-----+----------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Build a Clustering Model with Spark with a dataset of your choice"
      ],
      "metadata": {
        "id": "ayAcNIQVQsUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.clustering import KMeans\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load and convert dataset\n",
        "iris = load_iris()\n",
        "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "spark_iris_df = spark.createDataFrame(iris_df)\n",
        "\n",
        "# Feature vector\n",
        "assembler = VectorAssembler(inputCols=iris.feature_names, outputCol=\"features\")\n",
        "iris_vec = assembler.transform(spark_iris_df)\n",
        "\n",
        "# KMeans\n",
        "kmeans = KMeans(k=3, seed=1)\n",
        "model = kmeans.fit(iris_vec)\n",
        "centers = model.clusterCenters()\n",
        "\n",
        "# Predictions\n",
        "preds = model.transform(iris_vec)\n",
        "preds.select(\"features\", \"prediction\").show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJMmCZelQPAc",
        "outputId": "554154a1-b6a1-4b51-e3e7-1b58cc3ebdd0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+----------+\n",
            "|         features|prediction|\n",
            "+-----------------+----------+\n",
            "|[5.1,3.5,1.4,0.2]|         1|\n",
            "|[4.9,3.0,1.4,0.2]|         1|\n",
            "|[4.7,3.2,1.3,0.2]|         1|\n",
            "|[4.6,3.1,1.5,0.2]|         1|\n",
            "|[5.0,3.6,1.4,0.2]|         1|\n",
            "+-----------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Build a Recommendation Engine with Spark with a dataset of your\n",
        "choice"
      ],
      "metadata": {
        "id": "f7CcPLXxQ0QP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
        "!unzip -o ml-latest-small.zip\n",
        "\n",
        "from pyspark.ml.recommendation import ALS\n",
        "\n",
        "# Load data\n",
        "ratings_df = pd.read_csv(\"ml-latest-small/ratings.csv\")\n",
        "ratings_df = ratings_df.drop(\"timestamp\", axis=1)\n",
        "spark_ratings_df = spark.createDataFrame(ratings_df)\n",
        "\n",
        "# ALS Model\n",
        "als = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
        "model = als.fit(spark_ratings_df)\n",
        "\n",
        "# Recommendations\n",
        "user_recs = model.recommendForAllUsers(3)\n",
        "user_recs.show(5, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vhw_bYsBQP4f",
        "outputId": "40a7c985-a53e-4601-f093-1c4b1975c5e3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-24 10:04:31--  https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 978202 (955K) [application/zip]\n",
            "Saving to: ‘ml-latest-small.zip’\n",
            "\n",
            "ml-latest-small.zip 100%[===================>] 955.28K   953KB/s    in 1.0s    \n",
            "\n",
            "2025-04-24 10:04:34 (953 KB/s) - ‘ml-latest-small.zip’ saved [978202/978202]\n",
            "\n",
            "Archive:  ml-latest-small.zip\n",
            "   creating: ml-latest-small/\n",
            "  inflating: ml-latest-small/links.csv  \n",
            "  inflating: ml-latest-small/tags.csv  \n",
            "  inflating: ml-latest-small/ratings.csv  \n",
            "  inflating: ml-latest-small/README.txt  \n",
            "  inflating: ml-latest-small/movies.csv  \n",
            "+------+------------------------------------------------------------+\n",
            "|userId|recommendations                                             |\n",
            "+------+------------------------------------------------------------+\n",
            "|1     |[{132333, 5.74244}, {5490, 5.74244}, {5915, 5.7160797}]     |\n",
            "|2     |[{131724, 4.9081984}, {4617, 4.736027}, {184245, 4.6864967}]|\n",
            "|3     |[{70946, 5.134517}, {6835, 4.903289}, {5746, 4.903289}]     |\n",
            "|4     |[{25825, 5.3920903}, {53127, 5.1736145}, {70994, 5.171753}] |\n",
            "|5     |[{720, 4.938437}, {132333, 4.782514}, {5490, 4.782514}]     |\n",
            "+------+------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QDyPcqprQYwp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}